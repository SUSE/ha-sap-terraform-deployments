---
groups:
  # sap alerts
  - name: sap-hana-resource-monitoring
    rules:
      - alert: sap-hana-master-resource-down
        expr: absent(ha_cluster_pacemaker_resources{resource=~"rsc_SAPHana_.*",role="master",status="active"} == 1)
        labels:
          severity: page
        annotations:
          summary: Primary SAP-HANA resource down

      - alert: sap-hana-secondary-resource-absent
        expr: absent(ha_cluster_pacemaker_resources{resource=~"rsc_SAPHana_.*",role="slave",status="active"} == 1)
        labels:
          severity: page
        annotations:
          summary: Slave SAP-HANA resource absent

      - alert: sap-hana-internal-alerts
        expr: hanadb_alerts_current_rating > 3
        labels:
          severity: page
        annotations:
          summary: "HANA Internal alert raised for SID {{ $labels.sid }} InsNr {{ $labels.insnr }} DBName {{ $labels.database_name }}"
          description: "Alert Details: {{ $labels.alert_details }} User Action: {{ $labels.alert_useraction }}"

  # ha cluster alerts
  - name: cluster-resources-monitoring
    rules:
      - alert: cluster-resources-a-resource-failed
        expr: count(ha_cluster_pacemaker_resources{status="failed"} == 1) > 0
        labels:
          severity: page
        annotations:
          summary: A cluster resource failed

  # failcount exceed migration threshold (example on saphana specific resource)
  - name: resource-failcount-higher-threshold
    rules:
      - alert: resource-failcount-higher-threshold
        expr: count(ha_cluster_pacemaker_fail_count > ha_cluster_pacemaker_migration_threshold) > 0
        labels:
          severity: page
        annotations:
          summary: a resource fail count exceeded its migration threshold

  # drbd alerts
  - name: drbd-alerts
    rules:
      - alert: drbd-connections-in-a-bad-state
        expr: count(ha_cluster_drbd_connections{peer_disk_state=~"inconsistent|outdated|dunknown|failed"}) > 0
        labels:
          severity: page
        annotations:
          summary: a drbd connection is an bad state inconsistent|outdated|dunknown|failed

      - alert: drbd-sync-connections-percentage-lower-than-expected
        expr: ha_cluster_drbd_connections_sync < 90
        labels:
          severity: page
        annotations:
          summary: a drbd disk sync is lower than 90 percent!

      - alert: drbd-resource-in-a-bad-state
        expr: count(ha_cluster_drbd_resources{peer_disk_state=~"inconsistent|outdated|dunknown|failed"}) > 0
        labels:
          severity: page
        annotations:
          summary: a drbd resource is an bad state inconsistent|outdated|dunknown|failed

  # sbd alerts
  - name: sbd-device-alerts
    rules:
      - alert: a-sbd-device-unhealthy
        expr: count(ha_cluster_sbd_devices{status="unhealthy"} == 1) > 0
        labels:
          severity: page
        annotations:
          summary: An SBD device in the HA cluster is unhealthy

  # systemd services alerts
  - name: systemd-services-monitoring
    rules:
      - alert: service-down-pacemaker
        expr: node_systemd_unit_state{name="pacemaker.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: Pacemaker service not running

      - alert: service-down-corosync
        expr: node_systemd_unit_state{name="corosync.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: Corosync service not running

      - alert: service-down-sbd
        expr: node_systemd_unit_state{name="sbd.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: SBD service not running

      - alert: service-down-hawk
        expr: node_systemd_unit_state{name="hawk.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: Hawk service not running

      - alert: service-down-hawk-backend
        expr: node_systemd_unit_state{name="hawk-backend.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: Hawk backend service not running

      - alert: service-down-node-exporter
        expr: node_systemd_unit_state{name="prometheus-node_exporter.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: Node exporter service not running

      - alert: service-down-ha-cluster-exporter
        expr: node_systemd_unit_state{name="prometheus-ha_cluster_exporter.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: HA Cluster Exporter service not running

      - alert: service-down-hanadb-exporter
        expr: node_systemd_unit_state{name=~"hanadb_exporter@.*.service", state="active"} == 0
        labels:
          severity: page
        annotations:
          summary: HANA exporter service not running

      - alert: node-filesystem-space-low
        expr: ((node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_avail_bytes) / node_filesystem_size_bytes * 100) > 85
        labels:
          severity: page
        annotations:
          summary: Node filesystem space usage is higher than 85%

      - alert: stonith-disabled
        expr: ha_cluster_pacemaker_stonith_enabled == 0
        labels:
          severity: page
        annotations:
          summary: STONITH is disabled! Clusters without a fencing mechanism are not supported and have increased risk of data loss.

      - alert: negative-location-constraint-detected
        expr: ha_cluster_pacemaker_location_constraints < 0
        labels:
          severity: warning
        annotations:
          summary: A negative resource location constraint has been detected. Please ensure that no resource has been mistakenly banned from a node.
